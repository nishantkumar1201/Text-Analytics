{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FYz0CdJmnK7t"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n"
      ],
      "metadata": {
        "id": "uQDwe5c1nfjN",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 140
        },
        "outputId": "94a821b5-eddb-4770-a825-88cc95840be2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\n# Download required resources\\nnltk.download(\\'punkt\\')\\nnltk.download(\\'stopwords\\')\\nnltk.download(\\'wordnet\\')\\n\\n# Sample dataset\\ndocuments = [\\n    \"The striped bats are hanging on their feet for best.\",\\n    \"Cats running faster than dogs in the wild.\",\\n    \"He studies studying studied at the university.\"\\n]\\n\\n# Initialize tools\\nstop_words = set(stopwords.words(\\'english\\'))\\nstemmer = PorterStemmer()\\nlemmatizer = WordNetLemmatizer()\\n\\n# Preprocessing pipeline\\nfor doc in documents:\\n    print(f\"\\nOriginal: {doc}\")\\n    \\n    # 1. Tokenization\\n    tokens = word_tokenize(doc.lower())\\n    print(f\"Tokens: {tokens}\")\\n    \\n    # 2. Stopword Removal\\n    filtered_tokens = [w for w in tokens if w not in stop_words]\\n    print(f\"Without Stopwords: {filtered_tokens}\")\\n    \\n    # 3. Stemming\\n    stemmed = [stemmer.stem(w) for w in filtered_tokens]\\n    print(f\"Stemmed: {stemmed}\")\\n    \\n    # 4. Lemmatization\\n    lemmatized = [lemmatizer.lemmatize(w) for w in filtered_tokens]\\n    print(f\"Lemmatized: {lemmatized}\")\\n    '"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download required resources\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y417EZVK-8Lp",
        "outputId": "ba445625-7cf7-4109-d5a6-73e3baf83878"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample dataset\n",
        "documents = [\n",
        "    \"The striped bats are hanging on their feet for best.\",\n",
        "    \"Cats running faster than dogs in the wild.\",\n",
        "    \"He studies studying studied at the university.\"]"
      ],
      "metadata": {
        "id": "hRt1aWOc_cgv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize tools\n",
        "stop_words = set(stopwords.words('english'))\n",
        "stemmer = PorterStemmer()\n",
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "sDTxWZFp_ipX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Preprocessing pipeline\n",
        "for doc in documents:\n",
        "    print(f\"\\nOriginal: {doc}\")\n",
        "\n",
        "    # 1. Tokenization\n",
        "    tokens = word_tokenize(doc.lower())\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "\n",
        "    # 2. Stopword Removal\n",
        "    filtered_tokens = [w for w in tokens if w not in stop_words]\n",
        "    print(f\"Without Stopwords: {filtered_tokens}\")\n",
        "\n",
        "    # 3. Stemming\n",
        "    stemmed = [stemmer.stem(w) for w in filtered_tokens]\n",
        "    print(f\"Stemmed: {stemmed}\")\n",
        "\n",
        "    # 4. Lemmatization\n",
        "    lemmatized = [lemmatizer.lemmatize(w) for w in filtered_tokens]\n",
        "    print(f\"Lemmatized: {lemmatized}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EqhYOmgI_rFZ",
        "outputId": "0f2ae0b5-ed07-4832-e1f2-3bb62fac6b6a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original: The striped bats are hanging on their feet for best.\n",
            "Tokens: ['the', 'striped', 'bats', 'are', 'hanging', 'on', 'their', 'feet', 'for', 'best', '.']\n",
            "Without Stopwords: ['striped', 'bats', 'hanging', 'feet', 'best', '.']\n",
            "Stemmed: ['stripe', 'bat', 'hang', 'feet', 'best', '.']\n",
            "Lemmatized: ['striped', 'bat', 'hanging', 'foot', 'best', '.']\n",
            "\n",
            "Original: Cats running faster than dogs in the wild.\n",
            "Tokens: ['cats', 'running', 'faster', 'than', 'dogs', 'in', 'the', 'wild', '.']\n",
            "Without Stopwords: ['cats', 'running', 'faster', 'dogs', 'wild', '.']\n",
            "Stemmed: ['cat', 'run', 'faster', 'dog', 'wild', '.']\n",
            "Lemmatized: ['cat', 'running', 'faster', 'dog', 'wild', '.']\n",
            "\n",
            "Original: He studies studying studied at the university.\n",
            "Tokens: ['he', 'studies', 'studying', 'studied', 'at', 'the', 'university', '.']\n",
            "Without Stopwords: ['studies', 'studying', 'studied', 'university', '.']\n",
            "Stemmed: ['studi', 'studi', 'studi', 'univers', '.']\n",
            "Lemmatized: ['study', 'studying', 'studied', 'university', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8a3pAnPw_4yv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}